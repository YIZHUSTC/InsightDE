To run Spark job:
1. In PostgreSQL, create a table by executing: `create table traffic(id text, location text, latitude double precision, longitude double precision, lanes int, type text, highway text, avgvolume00 double precision, avgvolume01 double precision, avgvolume02 double precision, avgvolume03 double precision, avgvolume04 double precision, avgvolume05 double precision, avgvolume06 double precision, avgvolume07 double precision, avgvolume08 double precision, avgvolume09 double precision, avgvolume10 double precision, avgvolume11 double precision, avgvolume12 double precision, avgvolume13 double precision, avgvolume14 double precision, avgvolume15 double precision, avgvolume16 double precision, avgvolume17 double precision, avgvolume18 double precision, avgvolume19 double precision, avgvolume20 double precision, avgvolume21 double precision, avgvolume22 double precision, avgvolume23 double precision, PRIMARY KEY (id));`
2. Change awsAccessKeyId and awsSecretAccessKey to your keys.
3. Change the IP address in run_spark.sh to your private IP address that hosts your Spark service, then execute run_spark.sh.
